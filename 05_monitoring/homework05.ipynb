{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLOps Zoomcamp 2023 - Session #5\n",
    "\n",
    "Author: Jos√© Victor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1 Prepare the dataset\n",
    "\n",
    "Start with `baseline_model_nyc_taxi_data.ipynb`. Download the March 2023 Green Taxi data. We will use this data to simulate a production usage of a taxi trip duration prediction service.\n",
    "\n",
    "What is the shape of the download data? How many rows are there?\n",
    "\n",
    "* (X) 72044\n",
    "* ( ) 78537\n",
    "* ( ) 62495\n",
    "* ( ) 54396"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72044"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet(path=\"data/green_tripdata_2023-03.parquet\")\n",
    "df.shape[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2 Metric\n",
    "\n",
    "Let's expand the number of data quality metrics we'd like to monitor! Please add one metric of your choice and a quantile value for the `fare_amount` column (`quantile=0.5`).\n",
    "\n",
    "Hint: explore evidently metric `ColumnQuantileMetric` (`from evidently.metrics import ColumnQuantileMetric`)\n",
    "\n",
    "What metric did you choose?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evidently.metrics import ColumnQuantileMetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ColumnQuantileMetric(type='evidently.metrics.data_quality.column_quantile_metric.ColumnQuantileMetric', options=Options(color=None, render=None, custom={}), column_name=ColumnName(type='evidently.base_metric.ColumnName', name='fare_amount', display_name='fare_amount', dataset=<DatasetType.MAIN: 'main'>, feature_class=None), quantile=0.5)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ColumnQuantileMetric(column_name=\"fare_amount\", quantile=0.5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prefect flow\n",
    "\n",
    "Let's update prefect tasks by giving them nice meaningful names, specifying a number of delays and retries.\n",
    "\n",
    "Hint: use `evidently_metrics_calculation.py` script as a starting point to implement your solution. Check the prefect docs to check task parameters.\n",
    "\n",
    "What is the correct way of doing that?\n",
    "\n",
    "* ( ) `@task(retries_num=2, retry_seconds=5, task_name=\"calculate metrics\")`\n",
    "* ( ) `@task(retries_num=2, retry_delay_seconds=5, name=\"calculate metrics\")`\n",
    "* ( ) `@task(retries=2, retry_seconds=5, task_name=\"calculate metrics\")`\n",
    "* (X) `@task(retries=2, retry_delay_seconds=5, name=\"calculate metrics\")` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4 Monitoring\n",
    "\n",
    "Let's start monitoring. Run expanded monitoring for a new batch of data (March 2023).\n",
    "\n",
    "What is the maximum value of metric `quantile=0.5` on the `fare_amount` column during March 2023 (calculated daily)?\n",
    "\n",
    "* ( ) 10\n",
    "* ( ) 12.5\n",
    "* ( ) 14\n",
    "* ( ) 14.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q5 Dashboard\n",
    "\n",
    "Finally, let's add panels with new added metrics to the dashboard. After we customize the dashboard lets save a dashboard config, so that we can access it later. Hint: click on \"Save dashboard\" to access JSON configuration of the dashboard. This configuration should be saved locally.\n",
    "\n",
    "Where to place a dashboard config file?\n",
    "\n",
    "* ( ) `project_folder` (05-monitoring)\n",
    "* ( ) `project_folder/config` (05-monitoring/config)\n",
    "* (X) `project_folder/dashboards` (05-monitoring/dashboards)\n",
    "* ( ) `project_folder/data` (05-monitoring/data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
